[
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html",
    "title": "Takehome_Ex01",
    "section": "",
    "text": "Road traffic accidents are a significant global issue, causing approximately 1.19 million deaths and leaving 20 to 50 million people with non-fatal injuries annually, according to the World Health Organization (WHO). Vulnerable road users, like pedestrians, cyclists, and motorcyclists, make up more than half of these fatalities, with most incidents occurring in low- and middle-income countries. Thailand, in particular, has one of the highest road traffic death rates in Southeast Asia, with around 20,000 deaths each year. Economic impacts are also substantial, costing countries about 3% of their GDP. In Thailand, national highways see the highest concentration of accidents, especially in straight road sections and other accident-prone zones like intersections and curves."
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex04/Inclass_04.html",
    "href": "Inclass_Ex/Inclass_Ex04/Inclass_04.html",
    "title": "In-class_Ex03",
    "section": "",
    "text": "pacman::p_load(sf, ggstatsplot, tmap, tidyverse , GWmodel)"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex04/Inclass_04.html#data-import-and-preparation",
    "href": "Inclass_Ex/Inclass_Ex04/Inclass_04.html#data-import-and-preparation",
    "title": "In-class_Ex03",
    "section": "Data Import and Preparation",
    "text": "Data Import and Preparation\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhunan &lt;- left_join(hunan_sf,hunan2012)%&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\nJoining with `by = join_by(County)`\n\n\n#left join\n\nhunan_sp = hunan%&gt;%\n  as_Spatial()\n\n#Determine adaptive bandwidth\n\nbw_AIC=bw.gwr(GDPPC~1,data= hunan_sp, approach = \"AIC\", adaptive = TRUE,\n             kernel=\"bisquare\", longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\nbw_AIC\n\n[1] 22\n\n\n#Computationing geograohically wrighted summary statistics\n\ngwstat=gwss(\n  data = hunan_sp, \n  vars = \"GDPPC\",\n  bw = bw_AIC,\n  kernel=\"bisquare\",\n  adaptive = TRUE, \n  longlat=T)\n\n#preparing the output data\n\ngwstat_df = as.data.frame(gwstat$SDF)\nhunan_gstat = cbind(hunan_sf,gwstat_df)\n\n#Visualizing geographically weighted summary statistics\n\ntm_shape(hunan_gstat)+tm_fill(\"GDPPC_LM\",\n                              n=5,\n                              style = \"quantile\") +\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title = \"Distributiuon of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.text.size = 1.2,\n            legend.height = 1.5,\n            legend.width = 1.5,\n            frame = TRUE)"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex02/Inclass_Ex02.html",
    "href": "Inclass_Ex/Inclass_Ex02/Inclass_Ex02.html",
    "title": "Inclass_Ex02",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex02\\Data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\nchildcare_sf &lt;- st_read(\"Data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex02\\Data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\n\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\"\n)\nspplot(gridded_kde_childcareSG_ad)"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex01/Data/MPSZ-2019.html",
    "href": "Inclass_Ex/Inclass_Ex01/Data/MPSZ-2019.html",
    "title": "ISSS626",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "7 Network Constrained Spatial Point Patterns Analysis 7.1 Overview Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\nto derive network kernel density estimation (NKDE), and to perform network G-function and k-function analysis 7.2 The Data In this study, we will analyse the spatial distribution of childcare centre in Punggol planning area. For the purpose of this study, two geospatial data sets will be used. They are:\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area. Punggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area. Both data sets are in ESRI shapefile format.\n7.3 Installing and launching the R packages In this hands-on exercise, four R packages will be used, they are:\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances. sf package provides functions to manage, processing, and manipulate Simple Features, a formal geospatial data standard that specifies a storage and access model of spatial geometries such as points, lines, and polygons. tmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\npacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n7.4 Data Import and Preparation The code chunk below uses st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare2=st_zm(childcare, drop = TRUE,\n        what = \"ZM\")\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n7.5 Visualising the Geospatial Data Before we jump into the analysis, it is a good practice to visualise the geospatial data. There are at least two ways to visualise the geospatial data. One way is by using plot() of Base R as shown in the code chunk below.\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\n\n\n\n\nTo visualise the geospatial data with high cartographic quality and interactive manner, the mapping function of tmap package can be used as shown in the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) + \n  tm_dots() + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n7.6 Network KDE (NKDE) Analysis In this section, we will perform NKDE analysis by using appropriate functions provided in spNetwork package.\n7.6.1 Preparing the lixels objects Before computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\nWhat can we learned from the code chunk above:\nThe length of a lixel, lx_length is set to 700m, and The minimum length of a lixel, mindist is set to 350m. After cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified\n7.6.2 Generating line centre points Next, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at center of the line based on the length of the line.\n7.6.3 Performing NKDE We are ready to computer the NKDE by using the code chunk below.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\ndensities &lt;- nkde(network, \n                  events = childcare2,\n                  w = rep(1, nrow(childcare2)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nWhat can we learn from the code chunk above?\nkernel_name argument indicates that quartic kernel is used. Are possible kernel methods supported by spNetwork are: triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform. method argument indicates that simple method is used to calculate the NKDE. Currently, spNetwork support three popular methods, they are: method=“simple”. This first method was presented by Xie et al. (2008) and proposes an intuitive solution. The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit. method=“discontinuous”. The method is proposed by Okabe et al (2008), which equally “divides” the mass density of an event at intersections of lixels. method=“continuous”. If the discontinuous method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive. Okabe et al (2008) proposed another version of the kernel, that divide the mass of the density at intersection but adjusts the density before the intersection to make the function continuous. The user guide of spNetwork package provide a comprehensive discussion of nkde(). You should read them at least once to have a basic understanding of the various parameters that can be used to calibrate the NKDE model.\n7.6.3.1 Visualising NKDE Before we can visualise the NKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\n\nkfun_childcare$plotk"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html",
    "title": "hands-on_Ex01-B",
    "section": "",
    "text": "In general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling human’s most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#overview",
    "title": "hands-on_Ex01-B",
    "section": "",
    "text": "In general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling human’s most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#getting-started",
    "title": "hands-on_Ex01-B",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#importing-data-into-r",
    "title": "hands-on_Ex01-B",
    "section": "2.3 Importing Data into R",
    "text": "2.3 Importing Data into R\n\n2.3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n2.3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\n2.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n2.3.4 Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\n2.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_b.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "hands-on_Ex01-B",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n2.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n2.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\n2.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n2.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n2.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n2.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data\n\nType the following code chunk.\n\npacman::p_load(sf, tidyverse)\n\nWhat we can learn from the code chunk above:\n\np_load function pf pacman package is used to install and load sf and tidyverse pacages into R environment.\n\n\n\nIn this section, you will learn how to import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name. Also note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\nIn this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time you will find plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\n\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\n\n\n\n\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame.\n\n\n\n\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: You should not confuse with st_intersection().\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nDIY: Calculate the density of pre-school by planning subzone.\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nThe solution:\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#importing-geospatial-data",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In this section, you will learn how to import the following geospatial data into R by using st_read() of sf package:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n\nThe code chunk below uses st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame. Note that when the input geospatial data is in shapefile format, two arguments will be used, namely: dsn to define the data path and layer to provide the shapefile name. Also note that no extension such as .shp, .dbf, .prj and .shx are needed.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In this sub-section, you will learn different ways to retrieve information related to the content of a simple feature data frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nNotice that the print only displays basic information of the feature class such as type of geometry, the geographic extent of the features and the coordinate system of the data.\n\n\n\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time you will find plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#working-with-projection",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "Besides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\n\n\n\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nWarning: You should not confuse with st_intersection().\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nDIY: Calculate the density of pre-school by planning subzone.\nThe solution:\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise1(A)",
    "section": "",
    "text": "In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nThe solution:\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02_a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02_a.html",
    "title": "Hands-on_Ex02_a",
    "section": "",
    "text": "1st Order Spatial Point Patterns Analysis Methods\n4.1 Overview Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\nevents such as crime, traffic accident and disease onset, or business services (coffee and fastfood outlets) or facilities such as childcare and eldercare. Using appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\nare the childcare centres in Singapore randomly distributed throughout the country? if the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n4.2 The data To provide answers to the questions above, three data sets will be used. They are:\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format. MP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg. CostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n4.3 Installing and Loading the R packages\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n4.4 Spatial Data Wrangling 4.4.1 Importing the spatial data\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex02\\Data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex02\\Data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex02\\Data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "8.1 Overview In this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able to:\nimport geospatial data using appropriate function(s) of sf package, import csv file using appropriate function of readr package, perform relational join using appropriate join function of dplyr package, compute spatial weights using appropriate functions of spdep package, and calculate spatially lagged variables using appropriate functions of spdep package. 8.2 The Study Area and Data Two data sets will be used in this hands-on exercise, they are:\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format. Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012. 8.2.1 Getting Started Before we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R."
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex01/Inclass_Ex01.html",
    "href": "Inclass_Ex/Inclass_Ex01/Inclass_Ex01.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": ":::{style=“font-size: 1.50em”}\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot)\n\n\nmpsz14_shp &lt;- st_read(dsn= \"Data/geospatial\", \n                      layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz14_kml &lt;- st_read(\"data/geospatial/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\n\nst_write(mpsz14_shp, \"data/MP14_SUBZONE_WEB_PL.kml\",delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\nmpsz14_kml &lt;- st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex01\\Data\\MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_kml &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex01\\Data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_shp = st_read(dsn = \"data/\", layer = \"MPSZ-2019\") %&gt;%\nst_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex01\\Data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\npopdata2023 &lt;- read_csv(\"data/aspatial/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13]) # Aged 25 - 59\n         + rowSums(.[15])) %&gt;% # Aged 60 - 64\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`) \n          / `ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`,\n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ),\n            .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2023, \"data/mpszpop2023.rds\")\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2023, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex03/Inclass_Ex03.html",
    "href": "Inclass_Ex/Inclass_Ex03/Inclass_Ex03.html",
    "title": "Inclass_Ex03",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)\n\n\nnetwork &lt;- st_read(dsn=\"data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare &lt;- st_read(dsn=\"data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `D:\\FuWanqian\\ISSS608-VAA\\Inclass_Ex\\Inclass_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\nchildcare2 = st_zm(childcare, drop = TRUE,\n        what = \"ZM\")\n\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                      geometry\n1   kml_10 POINT Z (36173.81 42550.33 0)\n2   kml_99 POINT Z (36479.56 42405.21 0)\n3  kml_100 POINT Z (36618.72 41989.13 0)\n4  kml_101 POINT Z (36285.37 42261.42 0)\n5  kml_122  POINT Z (35414.54 42625.1 0)\n6  kml_161 POINT Z (36545.16 42580.09 0)\n7  kml_172 POINT Z (35289.44 44083.57 0)\n8  kml_188 POINT Z (36520.56 42844.74 0)\n9  kml_205  POINT Z (36924.01 41503.6 0)\n10 kml_222 POINT Z (37141.76 42326.36 0)\n\n\n\nnetwork\n\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     LINK_ID                   ST_NAME                       geometry\n1  116130894                PUNGGOL RD LINESTRING (36546.89 44574....\n2  116130897 PONGGOL TWENTY-FOURTH AVE LINESTRING (36546.89 44574....\n3  116130901   PONGGOL SEVENTEENTH AVE LINESTRING (36012.73 44154....\n4  116130902   PONGGOL SEVENTEENTH AVE LINESTRING (36062.81 44197....\n5  116130907           PUNGGOL CENTRAL LINESTRING (36131.85 42755....\n6  116130908                PUNGGOL RD LINESTRING (36112.93 42752....\n7  116130909           PUNGGOL CENTRAL LINESTRING (36127.4 42744.5...\n8  116130910               PUNGGOL FLD LINESTRING (35994.98 42428....\n9  116130911               PUNGGOL FLD LINESTRING (35984.97 42407....\n10 116130912            EDGEFIELD PLNS LINESTRING (36200.87 42219....\n\n\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\n\n\n\n\n\nplot(network)\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\n\n\n\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) + \n  tm_dots(col=\"red\") + \n  tm_shape(network) +\n  tm_lines()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\n\nsamples &lt;- lines_center(lixels) \n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines(col = 'blue') +\n  tm_shape(samples) +\n  tm_dots() \n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\ndensities &lt;- nkde(network, \n                  events = childcare2,\n                  w = rep(1, nrow(childcare2)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\ndensities1 &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\")\n\n[1] \"checking inputs ...\"\n[1] \"prior data preparation ...\"\n[1] \"Splitting the data with the spatial grid ...\"\n[1] \"start calculating the kernel values ...\"\n[1] \"    quadra 1/1\"\n[1] \"    build graph ...\"\n[1] \"        calculating NKDE values ...\"\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%[1] \"combining the results ...\"\n\n\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nkfun_childcare &lt;- kfunctions(network, \n                             childcare,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\nkfun_childcare$plotk"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626",
    "section": "",
    "text": "Welcome to My Page. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#loading-packages",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#loading-packages",
    "title": "Takehome_Ex01",
    "section": "3.1 Loading Packages",
    "text": "3.1 Loading Packages\n\npacman::p_load(sf, tidyverse, tmap, spNetwork, sp,spatstat ,dplyr)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-collect",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-collect",
    "title": "Takehome_Ex01",
    "section": "3.2 Data Collect",
    "text": "3.2 Data Collect\nThree data sets are used in this exercise, they are:\n\nThailand Road Accident [2019-2022] on Kaggle. This dataset offers comprehensive statistics on road accidents recorded in Thailand from approximately 2019 to 2022, covering various aspects of the incidents.\nThailand Roads (OpenStreetMap Export) on HDX. This dataset, sourced from OpenStreetMap, provides a detailed map of Thailand’s road network.\nThailand - Subnational Administrative Boundaries on HDX. This dataset provides comprehensive geographic data on Thailand’s subnational administrative boundaries, covering provinces, districts, and subdistricts."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-preparation",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-preparation",
    "title": "Takehome_Ex01",
    "section": "4.1 Data Preparation",
    "text": "4.1 Data Preparation\n\n4.4.1 Data import\n\nacc &lt;- read.csv(\"data/aspatical/thai_road_accident_2019_2022.csv\") \n\n\ntr &lt;- st_read(dsn=\"data/geospatial\", layer = 'hotosm_tha_roads_lines_shp')\n\n\nad &lt;- st_read(dsn=\"data/geospatial\", layer = 'tha_admbnda_adm1_rtsd_20220121')\n\nHere we first import the administrative level 1 data, which includes the provincial boundaries of Thailand.\n\n\n4.4.2 Data selection\n\nbmr_acc&lt;- acc %&gt;%\n  filter(province_en %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Pathum Thani\", \n                        \"Nonthaburi\", \"Samut Prakan\", \"Samut Sakhon\"))\n\n\nbmr_ad&lt;- ad %&gt;%\n  filter(ADM1_EN %in% c(\"Bangkok\", \"Nakhon Pathom\", \"Pathum Thani\", \n                        \"Nonthaburi\", \"Samut Prakan\", \"Samut Sakhon\"))\n\nHere we filter the BMR data from both the accident data and the provincial boundary data of Thailand.”\n\n\n4.4.3 Drop missing value for accident data\n\nmissing_coords &lt;- bmr_acc[is.na(bmr_acc$longitude) | is.na(bmr_acc$latitude), ]\n\nmissing_coords_count &lt;- nrow(missing_coords)\n\nmissing_coords_count\n\nThe number of missing coordinates is 350, so using below codes to drop missing value.\n\nbmr_acc2 &lt;- bmr_acc[!is.na(bmr_acc$longitude) & !is.na(bmr_acc$latitude), ]\n\n\n\n4.4.4 Transform data format\nIt is important for us to ensure that all the data are projected in same projection system, then here we transform BMR accident data and BMR boundary to EPSG:32647 (UTM Zone 47N).\n\nbmr_acc_data &lt;- st_as_sf(bmr_acc2, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nbmr_acc_data_utm &lt;- st_transform(bmr_acc_data, crs = 32647)\nbmr_acc_data_utm\n\nSimple feature collection with 12986 features and 16 fields\nGeometry type: POINT Dimension: XY\nBounding box: xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n\nbmr_ad_data_utm &lt;- st_transform(bmr_ad, crs = 32647)\nbmr_ad_data_utm\n\nSimple feature collection with 6 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension: XY\nBounding box: xmin: 587893.5 ymin: 1484414 xmax: 712440.5 ymax: 1579076\nProjected CRS: WGS 84 / UTM zone 47N"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#mapping-the-data",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#mapping-the-data",
    "title": "Takehome_Ex01",
    "section": "4.2 Mapping the data",
    "text": "4.2 Mapping the data\n\nplot(st_geometry(bmr_ad_data_utm), col = \"lightgrey\", border = \"black\", main = \"BMR Accident Locations (Base R)\")\n\nplot(st_geometry(bmr_acc_data_utm), col = \"black\", pch = 19, cex = 0.1, add = TRUE)  \n\ntm_shape(bmr_ad_data_utm) +\n  tm_borders(col = \"black\", lwd = 1) +   borders\n  tm_shape(bmr_acc_data_utm) +\n  tm_dots(col = \"black\", size = 0.01) +  \n  tm_layout(title = \"BMR Accident Locations (tmap)\")\n\n\n\n\n\n\n\n\nThe first plot shows the locations of traffic accidents in the Bangkok Metropolitan Region, with black dots concentrated in the city center and along major roads, especially near intersections and busy traffic areas. Accident density varies across different provinces, with hotspots mainly distributed along major roads."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#convert-data-to-ppp-format",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#convert-data-to-ppp-format",
    "title": "Takehome_Ex01",
    "section": "4.3 Convert data to ppp format",
    "text": "4.3 Convert data to ppp format\n\n4.3.1 sp format\n\nbmr_acc_data_sp &lt;- as_Spatial(bmr_acc_data_utm)\nbmr_boundary_sp &lt;- as_Spatial(bmr_ad_data_utm)\n\n\n\n4.3.2 ppp format\n\nacc_coords &lt;- coordinates(bmr_acc_data_sp)\nbbox_values &lt;- bbox(bmr_boundary_sp)\n\n\nbmr_window &lt;- owin(xrange = c(bbox_values[1, 1], bbox_values[1, 2]), \n                   yrange = c(bbox_values[2, 1], bbox_values[2, 2]))\n\n\nbmr_acc_ppp &lt;- ppp(x = acc_coords[, 1], y = acc_coords[, 2], window = bmr_window)\nplot(bmr_acc_ppp, main = \"BMR Accident Locations\", cex = 0.5)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#handling-duplicate-points",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#handling-duplicate-points",
    "title": "Takehome_Ex01",
    "section": "4.4 Handling duplicate points",
    "text": "4.4 Handling duplicate points\n\n4.4.1 check duplicates\n\nsum(multiplicity(bmr_acc_ppp) &gt; 1)\n\n\n\n4.4.2 Apply jitter to handle duplicates\n\nbmr_acc_ppp_jit &lt;- rjitter(bmr_acc_ppp, retry = TRUE, nsim = 1, drop = TRUE)\nany(duplicated(bmr_acc_ppp_jit))"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#combine-point-events-object-and-owin-object",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#combine-point-events-object-and-owin-object",
    "title": "Takehome_Ex01",
    "section": "4.5 Combine point events object and owin object",
    "text": "4.5 Combine point events object and owin object\n\nbmr_acc_ppp_final &lt;- bmr_acc_ppp_jit[bmr_window]"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#kernel-density-estimation-kde-analysis",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#kernel-density-estimation-kde-analysis",
    "title": "Takehome_Ex01",
    "section": "4.6 Kernel Density Estimation (KDE) Analysis",
    "text": "4.6 Kernel Density Estimation (KDE) Analysis\n\nsigma_value &lt;- 12000  \nkde_bmr_acc &lt;- density(bmr_acc_ppp_final,  \n                       sigma = sigma_value, \n                       edge = TRUE,  \n                       kernel = \"gaussian\")  \n\n\nplot(kde_bmr_acc, main = \"KDE of Accident Data\")\nplot(st_geometry(bmr_ad_data_utm), add = TRUE, border = \"black\", lwd = 2)\n\nFrom the map, it is clear that central Bangkok and parts of Samut Prakan exhibit the highest density of car accidents, indicating that accidents are more concentrated in these urban areas. In contrast, the outer regions such as Nakhon Pathom, Pathum Thani, and Nonthaburi show much lower accident densities."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#g-function",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#g-function",
    "title": "Takehome_Ex01",
    "section": "4.7 G Function",
    "text": "4.7 G Function\nNull Hypothesis (H0): The spatial distribution of car accidents follows a completely spatially random (CSR) pattern, meaning that accidents occur independently and uniformly over the study area.\nAlternative Hypothesis (H1): The spatial distribution of car accidents is not random and exhibits clustering or dispersion, implying that accidents are more likely to occur near each other or further apart than expected under CSR.\n\nG_CK = Gest(bmr_acc_ppp_final, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\nThe plot shows that the observed G function (black line) rises more quickly than the expected Poisson function (red dashed line), indicating that car accidents are spatially clustered."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-select",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#data-select",
    "title": "Takehome_Ex01",
    "section": "5.1 Data select",
    "text": "5.1 Data select\nLots of side roads in the road data may influence the accuracy of the NKDE results, so here we filter the dataset to include only major roads.\n\nmain_rd &lt;- tr %&gt;%\n  filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\"))\nsaveRDS(main_rd,\"data/geospatial/main_rd.rds\")\n\nHere we select bangkok city boundary.\n\nselected_cities &lt;- c(\"Bangkok\")\n\nbangkok_city &lt;- bmr_ad_data_utm %&gt;%\n  filter(ADM1_EN %in% selected_cities)\n\nsaveRDS(bangkok_city,\"data/geospatial/bmr_city.rds\")\n\nThen we select the main roads within Bangkok by intersecting the road and city boundary datasets.\n\nmain_rd_format &lt;- st_transform(main_rd, crs = 32647)\nsaveRDS(main_rd_format,\"data/geospatial/main_rd_format.rds\")\n\n\nmain_bangkok_roads &lt;- st_intersection(main_rd_format, bangkok_city)\n\n\nsaveRDS(main_bangkok_roads, \"data/geospatial/main_bangkok_roads2.rds\")\n\n\nmain_bangkok_roads &lt;- readRDS(\"data/geospatial/main_bangkok_roads2.rds\")\n\nFilters the accident data to include only records from the Bangkok province.\n\nbangkok_acc &lt;- bmr_acc_data_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#transfer-to-linestring",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#transfer-to-linestring",
    "title": "Takehome_Ex01",
    "section": "5.2 Transfer to linestring",
    "text": "5.2 Transfer to linestring\n\nmain_bangkok_roads &lt;- main_bangkok_roads %&gt;%\n  filter(st_geometry_type(main_bangkok_roads) %in% c(\"LINESTRING\", \"MULTILINESTRING\"))\n\n\nmain_bangkok_roads &lt;- st_cast(main_bangkok_roads, \"LINESTRING\", group_or_split = TRUE)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#generate-lixels",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#generate-lixels",
    "title": "Takehome_Ex01",
    "section": "5.3 Generate lixels",
    "text": "5.3 Generate lixels\n\nlixels_bangkok &lt;- lixelize_lines(main_bangkok_roads,\n                         10000,        \n                         mindist = 5000) \n\n\nsamples_bangkok &lt;- lines_center(lixels_bangkok)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#perform-nkde",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#perform-nkde",
    "title": "Takehome_Ex01",
    "section": "5.4 Perform NKDE",
    "text": "5.4 Perform NKDE\n\nnkde_result_bangkok &lt;- nkde(\n  lines = lixels_bangkok,                      \n  events = bangkok_acc,                     \n  w = rep(1, nrow(bangkok_acc)),            \n  samples = samples_bangkok,                   \n  kernel_name = \"quartic\",                     \n  bw = 500,                                    \n  div = \"bw\",                                  \n  method = \"simple\",                          \n  grid_shape = c(200, 200),                    \n  verbose = TRUE                               \n)\n\n\nnkde_result_bangkok &lt;- readRDS(\"data/aspatical/nkde_result_bangkok.rds\")\n\nhead(nkde_result_bangkok, 10)"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#visualize-nkde-results",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#visualize-nkde-results",
    "title": "Takehome_Ex01",
    "section": "5.5 Visualize NKDE results",
    "text": "5.5 Visualize NKDE results\n\nsamples_bangkok$density &lt;- nkde_result_bangkok\nlixels_bangkok$density &lt;- nkde_result_bangkok\n\n\nsamples_bangkok$density &lt;- samples_bangkok$density * 10000\nlixels_bangkok$density &lt;- lixels_bangkok$density * 10000\n\n\ntmap_mode('view')\n\ntm_shape(lixels_bangkok) +\n  tm_lines(col = \"density\", palette = \"YlOrRd\", title.col = \"Density\", lwd = 2) +\n  tm_shape(bangkok_acc) +\n  tm_dots(size = 0.1, col = \"blue\", alpha = 0.5, title = \"Accidents\")\n\ntmap_mode('plot')\n\nFrom above plot, the traffic accidents are almost entirely concentrated along the road network, particularly in the main roads and intersections of central Bangkok. The highest accident density is found along the main roads in central Bangkok, particularly in areas like Phra Nakhon, Pathum Wan, and Sathon. These indicate high-risk zones for accidents. In contrast, outer areas such as Nonthaburi and Samut Prakan have much lower accident densities, suggesting fewer incidents, likely due to lower traffic volumes or more dispersed road networks."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#split-time",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#split-time",
    "title": "Takehome_Ex01",
    "section": "6.1 Split time",
    "text": "6.1 Split time\nHere we divide the day into six time intervals.\n\nbmr_acc$incident_datetime &lt;- as.POSIXct(bmr_acc$incident_datetime, format=\"%Y/%m/%d %H:%M\")\n\n\nbmr_acc$hour &lt;- hour(bmr_acc$incident_datetime)\n\nbmr_acc$time_period &lt;- cut(bmr_acc$hour, \n                           breaks = seq(0, 24, by = 2), \n                           include.lowest = TRUE, \n                           labels = FALSE)\n\n\naccident_count &lt;- bmr_acc %&gt;%\n  group_by(time_period) %&gt;%\n  summarise(count = n())\n\ntime_labels &lt;- c(\"00:00-02:00\", \"02:00-04:00\", \"04:00-06:00\", \"06:00-08:00\", \n                 \"08:00-10:00\", \"10:00-12:00\", \"12:00-14:00\", \"14:00-16:00\", \n                 \"16:00-18:00\", \"18:00-20:00\", \"20:00-22:00\", \"22:00-24:00\")\n\n\nggplot(accident_count, aes(x = factor(time_period, labels = time_labels), y = count)) +\n  geom_line(group=1, color=\"blue\") +\n  geom_point(color=\"red\") +\n  labs(title = \"Car Accident Count by Time of Day\", x = \"Time Period\", y = \"Accident Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nFrom the line plot above, we can see that the 08:00-10:00 has the highest accident count and 22:00-24:00 has the lowest count. Therefore, we will focus on these two time intervals for further analysis."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-kde-analysis-for-bmr",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-kde-analysis-for-bmr",
    "title": "Takehome_Ex01",
    "section": "6.2 Time KDE analysis for BMR",
    "text": "6.2 Time KDE analysis for BMR\n\n6.2.1 create new data frame\n\nbmr_acc$hour &lt;- as.numeric(format(bmr_acc$incident_datetime, \"%H\"))\n\n\nbmr_acc$time_period_flag &lt;- ifelse(bmr_acc$hour &gt;= 8 & bmr_acc$hour &lt; 10, \"08:00-10:00\", \n                            ifelse(bmr_acc$hour &gt;= 22 & bmr_acc$hour &lt; 24, \"22:00-24:00\", NA))\n\n\nfiltered_acc &lt;- bmr_acc %&gt;%\n  filter(!is.na(time_period_flag))\n\npeak_acc &lt;- filtered_acc %&gt;%\n  filter(time_period_flag == \"08:00-10:00\")\n\nnon_peak_acc &lt;- filtered_acc %&gt;%\n  filter(time_period_flag == \"22:00-24:00\")\n\n\n\n6.2.2 Transform accident data to EPSG:32647 (UTM Zone 47N)\n\npeak_acc_clean &lt;- peak_acc %&gt;%\n  filter(!is.na(longitude) & !is.na(latitude))\n\npeak_acc_sf &lt;- st_as_sf(peak_acc_clean, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\npeak_acc_utm &lt;- st_transform(peak_acc_sf, crs = 32647)\n\n\nnon_peak_acc_clean &lt;- non_peak_acc %&gt;%\n  filter(!is.na(longitude) & !is.na(latitude))\n\nnon_peak_acc_sf &lt;- st_as_sf(non_peak_acc_clean, coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nnon_peak_acc_utm &lt;- st_transform(non_peak_acc_sf, crs = 32647)\n\n\n\n6.2.3 Convert data to ppp\n\npeak_acc_utm_sp &lt;- as_Spatial(peak_acc_utm)\nnonpeak_acc_utm_sp &lt;- as_Spatial(non_peak_acc_utm)\n\nbmr_boundary_sp &lt;- as_Spatial(bmr_ad_data_utm)\n\n\npeak_acc_coords &lt;- coordinates(peak_acc_utm_sp)\nnonpeak_acc_coords &lt;- coordinates(nonpeak_acc_utm_sp)\n\nbbox_values &lt;- bbox(bmr_boundary_sp)\n\n\nbmr_window &lt;- owin(xrange = c(bbox_values[1, 1], bbox_values[1, 2]), \n                   yrange = c(bbox_values[2, 1], bbox_values[2, 2]))\n\n\npeak_bmr_acc_ppp &lt;- ppp(x = peak_acc_coords[, 1], y = peak_acc_coords[, 2], window = bmr_window)\n\nnonpeak_bmr_acc_ppp &lt;- ppp(x = nonpeak_acc_coords[, 1], y = nonpeak_acc_coords[, 2], window = bmr_window)\n\n\n\n6.2.4 Handling duplicate points\n\npeak_bmr_acc_jit &lt;- rjitter(peak_bmr_acc_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nnonpeak_bmr_acc_jit &lt;- rjitter(nonpeak_bmr_acc_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nCheck for duplicates after jittering\n\nany(duplicated(peak_bmr_acc_jit))\nany(duplicated(nonpeak_bmr_acc_jit))\n\n\n\n6.2.5 Combine point events object and owin object\n\npeak_bmr_acc_final &lt;- peak_bmr_acc_jit[bmr_window]\nnonpeak_bmr_acc_final &lt;- nonpeak_bmr_acc_jit[bmr_window]\n\n\n\n6.2.6 Kernel Density Estimation (KDE) Analysis\n\nsigma_value &lt;- 5000  \n\n\npeak_kde_bmr_acc &lt;- density(peak_bmr_acc_final,  \n                       sigma = sigma_value,  \n                       edge = TRUE,  \n                       kernel = \"gaussian\")  \n\n\nsigma_value &lt;- 5000  \n\n\n\nnonpeak_kde_bmr_acc &lt;- density(nonpeak_bmr_acc_final,  #\n                       sigma = sigma_value,  \n                       edge = TRUE,  \n                       kernel = \"gaussian\")  \n\n\nplot(peak_kde_bmr_acc, main = \"KDE of Accident Data(peak)\")\nplot(st_geometry(bmr_ad_data_utm), add = TRUE, border = \"black\", lwd = 2)\n\n\nplot(nonpeak_kde_bmr_acc, main = \"KDE of Accident Data(non-peak)\")\nplot(st_geometry(bmr_ad_data_utm), add = TRUE, border = \"black\", lwd = 2)\n\nIn the peak image, we can see the accident hotspots are mainly concentrated in the city center of Bangkok and surrounding areas. These areas likely experience a higher frequency of accidents due to the heavy traffic flow and commuter pressure. Additionally, in the western part of Bangkok, accident density is also significant. This indicates that during peak hours, accidents are not only concentrated in the core city but also extend to outer areas connected to the city, where traffic pressure is also high.\nIn the non-peak period image, the distribution of accidents appears more dispersed, though the central and surrounding areas of Bangkok still remain hotspots. Compared to the peak period, the frequency of accidents has reduced, and the areas of concentration have become smaller. In non-peak times, the western part of the city sees a decrease in accident density, with fewer hotspots overall, particularly in areas farther from the core city. The smaller yellow regions indicate fewer accidents when the traffic flow is lower, showing that during non-peak hours, although accidents still occur, they are less frequent, and their distribution is more spread out across the region."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-kde-for-bangkok",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-kde-for-bangkok",
    "title": "Takehome_Ex01",
    "section": "6.3 Time KDE for bangkok",
    "text": "6.3 Time KDE for bangkok\nFrom the time KDE for BMR, we can find that Bangkok has a higher car accident density in both time intervals. Therefore, we narrow our focus to Bangkok to examine the city’s accident distribution in more detail.\n\n6.3.1 select data\nacc data\n\npeak_bangkok_acc &lt;- peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\n\nnonpeak_bangkok_acc &lt;- non_peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\nbangkok district data\n\nbangkok_district &lt;- st_read(dsn = \"data/geospatial\",\n                        layer = \"tha_admbnda_adm2_rtsd_20220121\")%&gt;%\n  filter(ADM1_EN == \"Bangkok\")\n\n\nbangkok_district_format &lt;- st_transform(bangkok_district, crs = 32647)\n\n\n\n6.3.2 Convert data to ppp\n\npeak_bangkok_acc_sp &lt;- as_Spatial(peak_bangkok_acc)\nnonpeak_bangkok_acc_sp &lt;- as_Spatial(nonpeak_bangkok_acc)\n\nbangkok_district_sp &lt;- as_Spatial(bangkok_district_format)\n\n\npeak_bangkok_acc_coords &lt;- coordinates(peak_bangkok_acc_sp)\nnonpeak_bangkok_acc_coords &lt;- coordinates(nonpeak_bangkok_acc_sp)\n\nbangkok_bbox_values &lt;- bbox(bangkok_district_sp)\n\n\nbangkok_window &lt;- owin(xrange = c(bangkok_bbox_values[1, 1], bangkok_bbox_values[1, 2]), \n                   yrange = c(bangkok_bbox_values[2, 1], bangkok_bbox_values[2, 2]))\n\n\npeak_bangkok_acc_ppp &lt;- ppp(x = peak_bangkok_acc_coords[, 1], y = peak_bangkok_acc_coords[, 2], window = bmr_window)\n\nnonpeak_bangkok_acc_ppp &lt;- ppp(x = nonpeak_bangkok_acc_coords[, 1], y = nonpeak_bangkok_acc_coords[, 2], window = bmr_window)\n\n\n\n6.3.3 Handling duplicate points\n\npeak_bangkok_acc_jit &lt;- rjitter(peak_bangkok_acc_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nnonpeak_bangkok_acc_jit &lt;- rjitter(nonpeak_bangkok_acc_ppp, retry = TRUE, nsim = 1, drop = TRUE)\n\nCheck for duplicates after jittering\n\nany(duplicated(peak_bangkok_acc_jit))\nany(duplicated(nonpeak_bangkok_acc_jit))\n\n\n\n6.3.4 Combine point events object and owin object\n\npeak_bangkok_acc_final &lt;- peak_bangkok_acc_jit[bangkok_window]\nnonpeak_bangkok_acc_final &lt;- nonpeak_bangkok_acc_jit[bangkok_window]\n\n\n\n6.3.5 Kernel Density Estimation (KDE) Analysis\n\nsigma_value2 &lt;- 5000  \n\n\npeak_kde_bangkok_acc &lt;- density(peak_bangkok_acc_final,  \n                       sigma = sigma_value2,  \n                       edge = TRUE,  \n                       kernel = \"gaussian\")  \n\n\nnonpeak_kde_bangkok_acc &lt;- density(nonpeak_bangkok_acc_final,  \n                       sigma = sigma_value2,  \n                       edge = TRUE,  \n                       kernel = \"gaussian\")  \n\n\nplot(peak_kde_bangkok_acc, main = \"KDE of Accident Data(bangkok peak)\")\nplot(st_geometry(bangkok_district_format), add = TRUE, border = \"black\", lwd = 2)\n\n\nplot(nonpeak_kde_bangkok_acc, main = \"KDE of Accident Data(bangkok non-peak)\")\nplot(st_geometry(bangkok_district_format), add = TRUE, border = \"black\", lwd = 2)\n\nDuring peak hours, accident hotspots in Bangkok are mainly concentrated in the central and western districts. The deep yellow and red areas indicate higher accident frequencies, especially in major commuting zones near the city center, such as Phra Nakhon, Bang Rak, and Wang Thonglang. The city center shows a strong concentration of accidents, indicating high traffic pressure, while the western areas, such as Thonburi and Bang Khun Thian, also have significant accident density, reflecting the traffic flow connecting these districts to the city center. In contrast, eastern and northern areas show lower accident density during peak hours, suggesting fewer incidents in these regions.\nDuring non-peak hours, the distribution of accidents becomes more dispersed, though central and western Bangkok remain hotspots. The overall density of accidents decreases compared to peak hours. The central districts continue to be key accident hotspots, particularly along major roads leading to commercial and busy areas. In the western part of the city, accident density also decreases, indicating less traffic pressure during off-peak times. However, accidents are more spread out during non-peak hours, especially in the eastern and western regions, reflecting a broader and more dispersed pattern of incidents."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#k-function",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#k-function",
    "title": "Takehome_Ex01",
    "section": "6.4 K function",
    "text": "6.4 K function\nFrom the above analysis, we can identify the high-density districts in Bangkok. We will then select these districts to conduct a K-function analysis, which will help us examine the spatial distribution of accidents within these areas.\n\n6.4.1 import acc data\n\nsaveRDS(peak_bangkok_acc,\"data/aspatical/peak_bangkok_acc.rds\")\n\n\npeak_bangkok_acc&lt;-readRDS('data/aspatical/peak_bangkok_acc.rds')\n\n\n\n6.4.2 intersection data\n\npeak_bangkok_district_acc &lt;- st_intersection(peak_bangkok_acc,bangkok_district_format)\n\n\n\n6.4.3 Saphan Sung, Khan Na Yao, Bueng Kum, Bang Kapi, Suan Luang\n\nkfunc_acc_data &lt;- peak_bangkok_district_acc %&gt;%\n  filter(ADM2_EN %in% c(\"Saphan Sung\", \"Khan Na Yao\", \"Bueng Kum\", \"Bang Kapi\", \"Suan Luang\"))\n\n\nkfunc_boundary &lt;- bangkok_district_format %&gt;%\n  filter(ADM2_EN %in% c(\"Saphan Sung\", \"Khan Na Yao\", \"Bueng Kum\", \"Bang Kapi\", \"Suan Luang\"))\n\n\nkfunc_road &lt;- st_join(main_bangkok_roads, kfunc_boundary)\n\n\nlixels_kfunc &lt;- lixelize_lines(kfunc_road,\n                         10000,\n                         mindist = 5000)         \n\n\nsamples_kfunc &lt;- lines_center(lixels_kfunc)\n\n\nkfun &lt;- kfunctions(kfunc_road,\n                             kfunc_acc_data,\n                             start = 0,\n                   end = 10000, \n                   step = 1000, \n                   width = 500, \n                   nsim = 50, \n                   resolution = 50,\n                   verbose = FALSE, \n                   conf_int = 0.05,\n                   agg = 100)\n\n\nkfun$plotk\n\nFrom the above plot, in the 0-2750 meter distance, the blue line is significantly above the shaded confidence envelope. This indicates that within this distance, car accidents are spatially clustered in the five selected zones. After this distance, the blue line tends to level off and remains within the shaded area, indicating that beyond 2750 meters, the distribution of accident points becomes more random or follows a pattern similar to spatial randomness. The flattening of the blue line suggests that the clustering effect diminishes as the distance increases, and the accident distribution becomes more spread out and less concentrated."
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-nkde",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-nkde",
    "title": "Takehome_Ex01",
    "section": "6.5 Time NKDE",
    "text": "6.5 Time NKDE\n\n6.5.1 acc data filter\n\npeak_bangkok_acc &lt;- peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\n\nnonpeak_bangkok_acc &lt;- non_peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\n\n\n6.5.2 peak density\n\npeak_nkde_result_bangkok &lt;- nkde(\n  lines = lixels_bangkok,                      \n  events = peak_bangkok_acc,                     \n  w = rep(1, nrow(peak_bangkok_acc)),            \n  samples = samples_bangkok,                   \n  kernel_name = \"quartic\",                     \n  bw = 500,                                    \n  div = \"bw\",                                  \n  method = \"simple\",                          \n  grid_shape = c(200, 200),                    \n  verbose = TRUE                               \n)\n\n\nsaveRDS(peak_nkde_result_bangkok,'data/aspatical/peak_nkde_result_bangkok.rds')\n\n\n\n6.5.3 non-peak density\n\nnonpeak_nkde_result_bangkok &lt;- nkde(\n  lines = lixels_bangkok,                      \n  events = nonpeak_bangkok_acc,                     \n  w = rep(1, nrow(nonpeak_bangkok_acc)),            \n  samples = samples_bangkok,                   \n  kernel_name = \"quartic\",                     \n  bw = 500,                                    \n  div = \"bw\",                                  \n  method = \"simple\",                          \n  grid_shape = c(200, 200),                    \n  verbose = TRUE                               \n)\n\n\nsaveRDS(peak_nkde_result_bangkok,'data/aspatical/peak_nkde_result_bangkok.rds')\n\n\nsaveRDS(nonpeak_nkde_result_bangkok,'data/aspatical/nonpeak_nkde_result_bangkok.rds')\n\n\n\n6.5.4 import data\n\npeak_nkde_result_bangkok &lt;- readRDS(\"data/aspatical/peak_nkde_result_bangkok.rds\")\n\nhead(peak_nkde_result_bangkok, 10)\n\n\nnonpeak_nkde_result_bangkok &lt;- readRDS(\"data/aspatical/nonpeak_nkde_result_bangkok.rds\")\n\nhead(nonpeak_nkde_result_bangkok, 10)\n\n\n\n6.5.5 visualize data\n\nsamples_bangkok$peak_density &lt;- peak_nkde_result_bangkok\nlixels_bangkok$peak_density &lt;- peak_nkde_result_bangkok\n\n\nsamples_bangkok$peak_density &lt;- samples_bangkok$peak_density * 10000\nlixels_bangkok$peak_density &lt;- lixels_bangkok$peak_density * 10000\n\n\nsamples_bangkok$nonpeak_density &lt;- nonpeak_nkde_result_bangkok\nlixels_bangkok$nonpeak_density &lt;- nonpeak_nkde_result_bangkok\n\n\nsamples_bangkok$nonpeak_density &lt;- samples_bangkok$nonpeak_density * 10000\nlixels_bangkok$nonpeak_density &lt;- lixels_bangkok$nonpeak_density * 10000\n\n\ntmap_mode('view')\n\ntm_shape(lixels_bangkok) +\n  tm_lines(col = \"peak_density\", palette = \"YlOrRd\", title.col = \"Density\", lwd = 2) +\n  tm_shape(peak_bangkok_acc) +\n  tm_dots(size = 0.1, col = \"blue\", alpha = 0.5, title = \"Accidents\")\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixels_bangkok) +\n  tm_lines(col = \"nonpeak_density\", palette = \"YlOrRd\", title.col = \"Density\", lwd = 2) +\n  tm_shape(nonpeak_bangkok_acc) +\n  tm_dots(size = 0.1, col = \"blue\", alpha = 0.5, title = \"Accidents\")\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-nkde-for-bangkok",
    "href": "Takehome_Ex/Takehome_Ex01/Takehome_Ex01.html#time-nkde-for-bangkok",
    "title": "Takehome_Ex01",
    "section": "6.5 Time NKDE for bangkok",
    "text": "6.5 Time NKDE for bangkok\n\n6.5.1 acc data filter\n\npeak_bangkok_acc &lt;- peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\n\nnonpeak_bangkok_acc &lt;- non_peak_acc_utm %&gt;%\n  filter(province_en %in% \"Bangkok\")\n\n\n\n6.5.2 peak density\n\npeak_nkde_result_bangkok &lt;- nkde(\n  lines = lixels_bangkok,                      \n  events = peak_bangkok_acc,                     \n  w = rep(1, nrow(peak_bangkok_acc)),            \n  samples = samples_bangkok,                   \n  kernel_name = \"quartic\",                     \n  bw = 500,                                    \n  div = \"bw\",                                  \n  method = \"simple\",                          \n  grid_shape = c(200, 200),                    \n  verbose = TRUE                               \n)\n\n\nsaveRDS(peak_nkde_result_bangkok,'data/aspatical/peak_nkde_result_bangkok.rds')\n\n\n\n6.5.3 non-peak density\n\nnonpeak_nkde_result_bangkok &lt;- nkde(\n  lines = lixels_bangkok,                      \n  events = nonpeak_bangkok_acc,                     \n  w = rep(1, nrow(nonpeak_bangkok_acc)),            \n  samples = samples_bangkok,                   \n  kernel_name = \"quartic\",                     \n  bw = 500,                                    \n  div = \"bw\",                                  \n  method = \"simple\",                          \n  grid_shape = c(200, 200),                    \n  verbose = TRUE                               \n)\n\n\nsaveRDS(peak_nkde_result_bangkok,'data/aspatical/peak_nkde_result_bangkok.rds')\n\n\nsaveRDS(nonpeak_nkde_result_bangkok,'data/aspatical/nonpeak_nkde_result_bangkok.rds')\n\n\n\n6.5.4 import data\n\npeak_nkde_result_bangkok &lt;- readRDS(\"data/aspatical/peak_nkde_result_bangkok.rds\")\n\nhead(peak_nkde_result_bangkok, 10)\n\n\nnonpeak_nkde_result_bangkok &lt;- readRDS(\"data/aspatical/nonpeak_nkde_result_bangkok.rds\")\n\nhead(nonpeak_nkde_result_bangkok, 10)\n\n\n\n6.5.5 visualize data\n\nsamples_bangkok$peak_density &lt;- peak_nkde_result_bangkok\nlixels_bangkok$peak_density &lt;- peak_nkde_result_bangkok\n\n\nsamples_bangkok$peak_density &lt;- samples_bangkok$peak_density * 10000\nlixels_bangkok$peak_density &lt;- lixels_bangkok$peak_density * 10000\n\n\nsamples_bangkok$nonpeak_density &lt;- nonpeak_nkde_result_bangkok\nlixels_bangkok$nonpeak_density &lt;- nonpeak_nkde_result_bangkok\n\n\nsamples_bangkok$nonpeak_density &lt;- samples_bangkok$nonpeak_density * 10000\nlixels_bangkok$nonpeak_density &lt;- lixels_bangkok$nonpeak_density * 10000\n\n\ntmap_mode('view')\n\ntm_shape(lixels_bangkok) +\n  tm_lines(col = \"peak_density\", palette = \"YlOrRd\", title.col = \"Density\", lwd = 2) +\n  tm_shape(peak_bangkok_acc) +\n  tm_dots(size = 0.1, col = \"blue\", alpha = 0.5, title = \"Accidents\")\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_shape(lixels_bangkok) +\n  tm_lines(col = \"nonpeak_density\", palette = \"YlOrRd\", title.col = \"Density\", lwd = 2) +\n  tm_shape(nonpeak_bangkok_acc) +\n  tm_dots(size = 0.1, col = \"blue\", alpha = 0.5, title = \"Accidents\")\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Inclass_Ex/Inclass_Ex05/Inclass_Ex05.html",
    "href": "Inclass_Ex/Inclass_Ex05/Inclass_Ex05.html",
    "title": "Inclass_Ex05",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse, tmap, sfdep)                                \n\n\nHunan_2012 &lt;- read.csv('data/aspatial/Hunan_2012.csv') \n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                         layer = \"hunan\")                          \n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)                             \n\n\nwm_q &lt;- hunan_GDPPC %/%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                        style = \"w\"),\n         .before = 1)                             \n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt) \n\nset.seed(1234)\n\n\nglobal_moran_perm(wm_q$GDPCC,\n                       wm_q$nb,\n                        wm_q$wt,\n                  nsim=99)\n\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1)%&gt;%\n  unnest(local_moran)\n\n#visualizing lisa map\n\nlisa_sig &lt;- lisa%&gt;%\n  filter(p_ii&lt;)\n\nwm_idw &lt;- hunan_GDPPC"
  }
]